{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在处理文件collection.sampled.tsv 读取文件的格式为('pid', 'passage')\n",
      "正在处理文件train_sample_queries.tsv 读取文件的格式为('qid', 'query')\n",
      "正在处理文件train_sample_passv2_qrels.tsv 读取文件的格式为('qid', 'mark', 'pid', 'rating')\n",
      "正在处理文件val_2021_53_queries.tsv 读取文件的格式为('qid', 'query')\n",
      "正在处理文件val_2021_passage_top100.txt 读取文件的格式为('qid', 'mark', 'pid', 'rank', 'score', 'sys_id')\n",
      "正在处理文件val_2021.qrels.pass.final.txt 读取文件的格式为('qid', 'mark', 'pid', 'rating')\n",
      "正在处理文件test_2022_76_queries.tsv 读取文件的格式为('qid', 'query')\n",
      "正在处理文件test_2022_passage_top100.txt 读取文件的格式为('qid', 'mark', 'pid', 'rank', 'score', 'sys_id')\n",
      "正在处理文件test_2022.qrels.pass.withDupes.txt 读取文件的格式为('qid', 'mark', 'pid', 'rating')\n"
     ]
    }
   ],
   "source": [
    "from utils import Data\n",
    "data_processor = Data(root_path=\"../\")\n",
    "data_processor.read_in_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection.sampled\n",
      "train_sample_queries\n",
      "train_sample_passv2_qrels\n",
      "val_2021_53_queries\n",
      "val_2021_passage_top100\n",
      "val_2021.qrels.pass.final\n",
      "test_2022_76_queries\n",
      "test_2022_passage_top100\n",
      "test_2022.qrels.pass.withDupes\n"
     ]
    }
   ],
   "source": [
    "for f in data_processor.dataset.keys():\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of passages:  126799\n"
     ]
    }
   ],
   "source": [
    "set_passage_id = set(data_processor.dataset['collection.sampled'].keys())\n",
    "print(\"Total number of passages: \", len(set_passage_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DocT5query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "t5_path = \"../model/docT5query/\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(t5_path)\n",
    "dt5q = T5ForConditionalGeneration.from_pretrained(t5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_queries(passage: str, prefix=\"text2query\", queries_num=2):\n",
    "    input = prefix + \": \" + passage\n",
    "    input_ids = tokenizer.encode(\n",
    "        input,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "    )\n",
    "    outputs = dt5q.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=512,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=queries_num,\n",
    "    )\n",
    "    generated_queries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return generated_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20000 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for qid, v in tqdm(data_processor.dataset['train_sample_passv2_qrels'].items()):\n",
    "    \n",
    "    query = data_processor.dataset['train_sample_queries'][qid]['query']\n",
    "    # print(f\"The question {qid} is: {query}\")\n",
    "\n",
    "    positive_pid = v.keys().__iter__().__next__()\n",
    "    positive_passage = data_processor.dataset['collection.sampled'][positive_pid]['passage']\n",
    "    # print(f\"The positive passage {positive_pid} is: {positive_passage}\")\n",
    "    sample_passage_id = random.sample(list(set_passage_id - set([positive_pid])), 10)\n",
    "    # print(sample_passage_id)\n",
    "    sampled_passages = [\n",
    "        nlp(data_processor.dataset['collection.sampled'][pid]['passage'])\n",
    "        for pid in sample_passage_id\n",
    "    ]\n",
    "    doc = nlp(positive_passage)\n",
    "    similarity = [\n",
    "        doc.similarity(sampled_passage)\n",
    "        for sampled_passage in sampled_passages\n",
    "    ]\n",
    "    # 选择相似度最低的4个passage作为负样本\n",
    "    negative_passages_id = [\n",
    "        sample_passage_id[i]\n",
    "        for i in np.argsort(similarity)[:4]\n",
    "    ]\n",
    "    # print(f\"The negative passages id are: {negative_passages_id}\")\n",
    "    negative_passages = [\n",
    "        data_processor.dataset['collection.sampled'][i]['passage']\n",
    "        for i in negative_passages_id\n",
    "    ]\n",
    "    # print(f\"The negative passages are: {negative_passages}\")\n",
    "    # print(f\"The similarity between the positive passage and sampled passages are: {similarity}\")\n",
    "    \n",
    "    # 根据正样本生成2个query\n",
    "    generated_queries = generate_queries(positive_passage)\n",
    "    # print(f\"The generated queries are: {generated_queries}\")\n",
    "    # break\n",
    "    generation_dict[qid] = {\n",
    "        \"positive_passage_id\": [positive_pid],\n",
    "        \"negative_passages_id\": negative_passages_id,\n",
    "        \"generated_queries\": generated_queries,\n",
    "    }\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1185869': {'positive_passage_id': ['msmarco_passage_08_840101254'],\n",
       "  'negative_passages_id': ['msmarco_passage_38_192481906',\n",
       "   'msmarco_passage_20_341886578',\n",
       "   'msmarco_passage_32_869755311',\n",
       "   'msmarco_passage_11_205128414'],\n",
       "  'generated_queries': ['which major achievement of the early 20th century was the manhattan project?',\n",
       "   'why was the manhattan project important?']}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
